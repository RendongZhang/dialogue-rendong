{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "atmospheric-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from sklearn import preprocessing \n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "solar-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing file header \n",
    "text = []\n",
    "labels = []\n",
    "with open(\"NAME_OF_FOLDER_HERE.csv\", newline=\"\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        text.append(row[0].strip())\n",
    "        labels.append(row[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "contrary-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation= string.punctuation\n",
    "punctuation = punctuation.replace('?', '')\n",
    "punctuation = punctuation.replace(\"'\", '')\n",
    "punctuation = punctuation.replace('{', \"\")\n",
    "punctuation = punctuation.replace(\"}\", \"\")\n",
    "punctuation = punctuation.replace(\"*\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "engaged-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = []\n",
    "for t in text: \n",
    "    #Converting to lowercase\n",
    "    t = t.lower()\n",
    "    #tokenizing the text \n",
    "    t = word_tokenize(t)\n",
    "    #Tokenizing text and removing punctuation at the same time\n",
    "    new_text = [i for i in t if i not in punctuation]\n",
    "    X_text.append(\" \".join(new_text).strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "demanding-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  ack\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "#the 13 classes as recognized by the label encoder\n",
    "classes= list(le.classes_)\n",
    "#print(classes)\n",
    "\n",
    "y_encoded = le.transform(labels)\n",
    "#Label for the first class \n",
    "print(\"Class: \", labels[0])\n",
    "#print(\"Class_encoded: \", y_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "residential-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-eleven",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "psychological-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X_text, y_encoded, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "attempted-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make an evaluation set by splitting 90/10 split on the training set\n",
    "#X_train2, X_eval, y_train2, y_eval = train_test_split(X_train, y_train, shuffle=True, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-execution",
   "metadata": {},
   "source": [
    "## Write data to files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "double-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/train.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\", \"label\"])\n",
    "    for i in range(len(X_train)):\n",
    "        writer.writerow([X_train[i], y_train[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "processed-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/test.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\", \"label\"])\n",
    "    for i in range(len(X_test)):\n",
    "        writer.writerow([X_test[i], y_test[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment for maing 3 files - train, validation, and test\n",
    "\"\"\"\n",
    "with open(\"Data/train.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\", \"label\"])\n",
    "    for i in range(len(X_train2)):\n",
    "        writer.writerow([X_train2[i], y_train2[i]])\n",
    "        \n",
    "with open(\"Data/eval.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\", \"label\"])\n",
    "    for i in range(len(X_eval)):\n",
    "        writer.writerow([X_eval[i], y_eval[i]])\n",
    "        \n",
    "with open(\"Data/test.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"text\", \"label\"])\n",
    "    for i in range(len(X_eval)):\n",
    "        writer.writerow([X_test[i], y_test[i]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-meter",
   "metadata": {},
   "source": [
    "## Split Data for KFold Cross validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "residential-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_before_kfold = [list(i) for i in list(zip(X_text, labels))]\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=47)\n",
    "data_after_kfold = kfold.split(data_before_kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train= [] #To save to use for BERT\n",
    "#data_train_encoded=[]\n",
    "data_test = []\n",
    "data_test_encoded =[]\n",
    "for train, test in data_after_kfold:\n",
    "    train_decoded = [data_before_kfold[i] for i in train]\n",
    "    test_decoded = [data_before_kfold[i] for i in test]\n",
    "    X_train = [i[0] for i in train_decoded ]\n",
    "    y_train = [i[1] for i in train_decoded ]\n",
    "    #print(y_train)\n",
    "    \n",
    "   \"\"\" \n",
    "    X_train_encoded=[X_encoded[i] for i in train]\n",
    "    y_train_encoded = le.transform(y_train)\n",
    "    data_train.append([X_train,y_train])\n",
    "    data_train_encoded.append([X_train_encoded, y_train_encoded])\n",
    "    \n",
    "    print(len(Counter(y_train)))\n",
    "    \"\"\"\n",
    "    print(\"Distribution\", Counter(y_train))\n",
    "    X_test = [i[0] for i in test_decoded]\n",
    "    y_test = [i[1] for i in test_decoded]\n",
    "    print(len(Counter(y_test)))\n",
    "    \n",
    "   \"\"\"\n",
    "    X_test_encoded = [ X_encoded[i] for i in test]\n",
    "    y_test_encoded = le.transform(y_test)\n",
    "    \n",
    "    data_test.append([X_test,y_test])\n",
    "    data_test_encoded.append([X_test_encoded, y_test_encoded])\n",
    "    \"\"\"\n",
    "    print(\"Distribution\", Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-teach",
   "metadata": {},
   "source": [
    "## Save split data into files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    with open(\"Data/split_train_\"+str(i)+\".csv\", \"w\", newline='') as csvf:\n",
    "        writer = csv.writer(csvf, delimiter=',')\n",
    "        writer.writerow([\"text\", \"label\"])\n",
    "        for l in range(len(data_train[i][0])):\n",
    "            writer.writerow([data_train[i][0][l], data_train_encoded[i][1][l]])\n",
    "            \n",
    "    with open(\"Data/split_test_\"+str(i)+\".csv\", \"w\", newline='') as csvf:\n",
    "        writer = csv.writer(csvf, delimiter=',')\n",
    "        writer.writerow([\"text\", \"label\"])\n",
    "        for l in range(len(data_test[i][0])):\n",
    "            writer.writerow([data_test[i][0][l], data_test_encoded[i][1][l]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
